{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9cf28f",
   "metadata": {},
   "source": [
    "# The data should be:\n",
    "## Folder containing: 3 folders with images (train,validation,test) and 3 json files (train.json, validation.json, test.json). The data can be downloaded from https://github.com/DS4SD/DocLayNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b31330",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/microsoft/unilm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37890ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r unilm/layoutlmv3/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd unilm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02a83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd layoutlmv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8159a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9292e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcde133",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/ec2-user/SageMaker/unilm/layoutlmv3/examples/object_detection/train_net.py --config-file /home/ec2-user/SageMaker/unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3.yaml --num-gpus 1 \\\n",
    "        MODEL.WEIGHTS /home/ec2-user/SageMaker/unilm/layoutlmv3/pytorch_model.bin  \\\n",
    "        OUTPUT_DIR /home/ec2-user/SageMaker/ResultFullData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2b8f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /home/ec2-user/SageMaker/unilm/layoutlmv3/examples/object_detection/train_net.py --config-file /home/ec2-user/SageMaker/unilm/layoutlmv3/examples/object_detection/cascade_layoutlmv3test.yaml --eval-only --num-gpus 1 \\\n",
    "        MODEL.WEIGHTS /home/ec2-user/SageMaker/unilm/layoutlmv3/model_final.pth \\\n",
    "        OUTPUT_DIR /home/ec2-user/SageMaker/testdoclaynet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b268a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ac8088",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMODEL:\\n  MASK_ON: True\\n  IMAGE_ONLY: True\\n  META_ARCHITECTURE: \"VLGeneralizedRCNN\"\\n  PIXEL_MEAN: [ 127.5, 127.5, 127.5 ]\\n  PIXEL_STD: [ 127.5, 127.5, 127.5 ]\\n  WEIGHTS: \"/path/to/models/layoutlmv3/pts/layoutlmv3-base/pytorch_model.bin\"\\n  BACKBONE:\\n    NAME: \"build_vit_fpn_backbone\"\\n  VIT:\\n    NAME: \"layoutlmv3_base\"\\n    OUT_FEATURES: [ \"layer3\", \"layer5\", \"layer7\", \"layer11\" ]\\n    DROP_PATH: 0.1\\n    IMG_SIZE: [ 224,224 ]\\n    POS_TYPE: \"abs\"\\n  ROI_HEADS:\\n    NAME: CascadeROIHeads\\n    IN_FEATURES: [ \"p2\", \"p3\", \"p4\", \"p5\" ]\\n    NUM_CLASSES: 11\\n  ROI_BOX_HEAD:\\n    CLS_AGNOSTIC_BBOX_REG: True\\n    NAME: \"FastRCNNConvFCHead\"\\n    NUM_FC: 2\\n    POOLER_RESOLUTION: 7\\n  ROI_MASK_HEAD:\\n    NAME: \"MaskRCNNConvUpsampleHead\"\\n    NUM_CONV: 4\\n    POOLER_RESOLUTION: 14\\n  FPN:\\n    IN_FEATURES: [ \"layer3\", \"layer5\", \"layer7\", \"layer11\" ]\\n  ANCHOR_GENERATOR:\\n    SIZES: [ [ 32 ], [ 64 ], [ 128 ], [ 256 ], [ 512 ] ]  # One size for each in feature map\\n    ASPECT_RATIOS: [ [ 0.5, 1.0, 2.0 ] ]  # Three aspect ratios (same for all in feature maps)\\n  RPN:\\n    IN_FEATURES: [ \"p2\", \"p3\", \"p4\", \"p5\", \"p6\" ]\\n    PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level\\n    PRE_NMS_TOPK_TEST: 1000  # Per FPN level\\n    # Detectron1 uses 2000 proposals per-batch,\\n    # (See \"modeling/rpn/rpn_outputs.py\" for details of this legacy issue)\\n    # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.\\n    POST_NMS_TOPK_TRAIN: 2000\\n    POST_NMS_TOPK_TEST: 1000\\nDATASETS:\\n  TRAIN: (\"publaynet_train\",)\\n  TEST: (\"publaynet_val\",)\\nSOLVER:\\n  GRADIENT_ACCUMULATION_STEPS: 1\\n  BASE_LR: 0.0002\\n  WARMUP_ITERS: 1000\\n  IMS_PER_BATCH: 2\\n  MAX_ITER: 270000\\n  CHECKPOINT_PERIOD: 4000\\n  LR_SCHEDULER_NAME: \"WarmupCosineLR\"\\n  AMP:\\n    ENABLED: True\\n  OPTIMIZER: \"ADAMW\"\\n  BACKBONE_MULTIPLIER: 1.0\\n  CLIP_GRADIENTS:\\n    ENABLED: True\\n    CLIP_TYPE: \"full_model\"\\n    CLIP_VALUE: 1.0\\n    NORM_TYPE: 2.0\\n  WARMUP_FACTOR: 0.01\\n  WEIGHT_DECAY: 0.05\\nTEST:\\n  EVAL_PERIOD: 2000\\nINPUT:\\n  CROP:\\n    ENABLED: True\\n    TYPE: \"absolute_range\"\\n    SIZE: (384, 600)\\n  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\\n  FORMAT: \"RGB\"\\nDATALOADER:\\n  FILTER_EMPTY_ANNOTATIONS: False\\nVERSION: 2\\nAUG:\\n  DETR: True\\nSEED: 42\\nOUTPUT_DIR: \"/path/to/models/layoutlmv3/fts/publaynet-base/\"\\nPUBLAYNET_DATA_DIR_TRAIN: \"/home/ec2-user/SageMaker/DocLayNet/train\"\\nPUBLAYNET_DATA_DIR_TEST: \"/home/ec2-user/SageMaker/unilm/layoutlmv3/examples/object_detection/active_learning/train\"\\n\\n#PUBLAYNET_DATA_DIR_TEST: \"/home/ec2-user/SageMaker/DocLayNet/validation\"\\n#PUBLAYNET_DATA_DIR_TRAIN: \"/home/ec2-user/SageMaker/DocLayNet100/train\"\\n#PUBLAYNET_DATA_DIR_TEST: \"/home/ec2-user/SageMaker/DocLayNet100/validation\"\\nCACHE_DIR: \"/home/ec2-user/SageMaker/ResultFullData\"\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#config file\n",
    "#MASK_ON: True only if you want segmentation\n",
    "'''\n",
    "MODEL:\n",
    "  MASK_ON: True\n",
    "  IMAGE_ONLY: True\n",
    "  META_ARCHITECTURE: \"VLGeneralizedRCNN\"\n",
    "  PIXEL_MEAN: [ 127.5, 127.5, 127.5 ]\n",
    "  PIXEL_STD: [ 127.5, 127.5, 127.5 ]\n",
    "  WEIGHTS: \"/path/to/models/layoutlmv3/pts/layoutlmv3-base/pytorch_model.bin\"\n",
    "  BACKBONE:\n",
    "    NAME: \"build_vit_fpn_backbone\"\n",
    "  VIT:\n",
    "    NAME: \"layoutlmv3_base\"\n",
    "    OUT_FEATURES: [ \"layer3\", \"layer5\", \"layer7\", \"layer11\" ]\n",
    "    DROP_PATH: 0.1\n",
    "    IMG_SIZE: [ 224,224 ]\n",
    "    POS_TYPE: \"abs\"\n",
    "  ROI_HEADS:\n",
    "    NAME: CascadeROIHeads\n",
    "    IN_FEATURES: [ \"p2\", \"p3\", \"p4\", \"p5\" ]\n",
    "    NUM_CLASSES: 11\n",
    "  ROI_BOX_HEAD:\n",
    "    CLS_AGNOSTIC_BBOX_REG: True\n",
    "    NAME: \"FastRCNNConvFCHead\"\n",
    "    NUM_FC: 2\n",
    "    POOLER_RESOLUTION: 7\n",
    "  ROI_MASK_HEAD:\n",
    "    NAME: \"MaskRCNNConvUpsampleHead\"\n",
    "    NUM_CONV: 4\n",
    "    POOLER_RESOLUTION: 14\n",
    "  FPN:\n",
    "    IN_FEATURES: [ \"layer3\", \"layer5\", \"layer7\", \"layer11\" ]\n",
    "  ANCHOR_GENERATOR:\n",
    "    SIZES: [ [ 32 ], [ 64 ], [ 128 ], [ 256 ], [ 512 ] ]  # One size for each in feature map\n",
    "    ASPECT_RATIOS: [ [ 0.5, 1.0, 2.0 ] ]  # Three aspect ratios (same for all in feature maps)\n",
    "  RPN:\n",
    "    IN_FEATURES: [ \"p2\", \"p3\", \"p4\", \"p5\", \"p6\" ]\n",
    "    PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level\n",
    "    PRE_NMS_TOPK_TEST: 1000  # Per FPN level\n",
    "    # Detectron1 uses 2000 proposals per-batch,\n",
    "    # (See \"modeling/rpn/rpn_outputs.py\" for details of this legacy issue)\n",
    "    # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.\n",
    "    POST_NMS_TOPK_TRAIN: 2000\n",
    "    POST_NMS_TOPK_TEST: 1000\n",
    "DATASETS:\n",
    "  TRAIN: (\"publaynet_train\",)\n",
    "  TEST: (\"publaynet_val\",)\n",
    "SOLVER:\n",
    "  GRADIENT_ACCUMULATION_STEPS: 1\n",
    "  BASE_LR: 0.0002\n",
    "  WARMUP_ITERS: 1000\n",
    "  IMS_PER_BATCH: 2\n",
    "  MAX_ITER: 270000\n",
    "  CHECKPOINT_PERIOD: 4000\n",
    "  LR_SCHEDULER_NAME: \"WarmupCosineLR\"\n",
    "  AMP:\n",
    "    ENABLED: True\n",
    "  OPTIMIZER: \"ADAMW\"\n",
    "  BACKBONE_MULTIPLIER: 1.0\n",
    "  CLIP_GRADIENTS:\n",
    "    ENABLED: True\n",
    "    CLIP_TYPE: \"full_model\"\n",
    "    CLIP_VALUE: 1.0\n",
    "    NORM_TYPE: 2.0\n",
    "  WARMUP_FACTOR: 0.01\n",
    "  WEIGHT_DECAY: 0.05\n",
    "TEST:\n",
    "  EVAL_PERIOD: 2000\n",
    "INPUT:\n",
    "  CROP:\n",
    "    ENABLED: True\n",
    "    TYPE: \"absolute_range\"\n",
    "    SIZE: (384, 600)\n",
    "  MIN_SIZE_TRAIN: (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
    "  FORMAT: \"RGB\"\n",
    "DATALOADER:\n",
    "  FILTER_EMPTY_ANNOTATIONS: False\n",
    "VERSION: 2\n",
    "AUG:\n",
    "  DETR: True\n",
    "SEED: 42\n",
    "OUTPUT_DIR: \"/path/to/models/layoutlmv3/fts/publaynet-base/\"\n",
    "PUBLAYNET_DATA_DIR_TRAIN: \"/home/ec2-user/SageMaker/DocLayNet/train\"\n",
    "PUBLAYNET_DATA_DIR_TEST: \"/home/ec2-user/SageMaker/unilm/layoutlmv3/examples/object_detection/active_learning/train\"\n",
    "\n",
    "#PUBLAYNET_DATA_DIR_TEST: \"/home/ec2-user/SageMaker/DocLayNet/validation\"\n",
    "#PUBLAYNET_DATA_DIR_TRAIN: \"/home/ec2-user/SageMaker/DocLayNet100/train\"\n",
    "#PUBLAYNET_DATA_DIR_TEST: \"/home/ec2-user/SageMaker/DocLayNet100/validation\"\n",
    "CACHE_DIR: \"/home/ec2-user/SageMaker/ResultFullData\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdeab90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67878a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38107d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc2ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567503f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c949d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dce71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05920ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0049a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae56ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02646b26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
